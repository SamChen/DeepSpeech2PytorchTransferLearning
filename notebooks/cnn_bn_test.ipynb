{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## extract paddlepaddle weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_parameter(file_name):\n",
    "    with open(file_name, 'rb') as f:\n",
    "        f.read(16)  # skip header.\n",
    "        return np.fromfile(f, dtype=np.float32)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After two conv layers, the output will be transform from an image to a sequence. The dim of each frame is 1312. \n",
    "The input image size is (161, X) where X is the length of the image. \n",
    "In paddlepaddle.v2, the kernel size of the conv1 is (11,41) and the kernel size of the conv2 is (11,21).\n",
    "In order to get correct output, I find that second-dim of both kernels is related to the fisrt-dim of the input image.\n",
    "\n",
    "So I guess I should switch the the position of these two dims for kernel, stride and padding in pytorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = load_parameter(\"baidu_models/baidu_en8k/params/___conv_0__.w0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# v2 to fluid: reshape to [ochannel, inchannel, filer_height, filer_width], height is x-axis while width is y-axis\n",
    "test = test.reshape(32, 1, 11,41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv = nn.Conv2d(1, 32, kernel_size=(11, 41), stride=(3, 2), padding=(5, 20), bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv.weight.data = torch.from_numpy(conv1_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in conv.parameters():\n",
    "    assert torch.all(torch.eq(i, torch.from_numpy(conv1_weights)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.rand((3,1,255, 161))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'torch.FloatTensor'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input.type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = conv(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 32, 85, 81])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 9.29311588e-02,  1.35485291e-01, -4.28381890e-01, ...,\n",
       "          -2.97493190e-01,  6.46222010e-02,  9.92319882e-02],\n",
       "         [-4.26919967e-01, -1.15375303e-01, -6.09744966e-01, ...,\n",
       "           2.34946698e-01, -3.63475271e-02,  2.28529319e-01],\n",
       "         [ 2.62146175e-01, -8.91227052e-02, -4.09002453e-01, ...,\n",
       "           1.52953044e-01,  1.15739137e-01, -5.51388562e-02],\n",
       "         ...,\n",
       "         [ 3.39823887e-02,  1.53475493e-01, -1.54391572e-01, ...,\n",
       "           1.09738052e-01, -3.44127007e-02,  3.09078366e-01],\n",
       "         [ 9.09232646e-02, -3.43415588e-02, -3.24262597e-04, ...,\n",
       "          -1.17909603e-01, -3.33734527e-02, -1.92636419e-02],\n",
       "         [ 2.30847187e-02, -1.79902717e-01, -6.95237964e-02, ...,\n",
       "          -3.12168628e-01,  1.49332166e-01, -5.31788319e-02]]],\n",
       "\n",
       "\n",
       "       [[[ 1.52736083e-02,  1.70024708e-02, -4.49127220e-02, ...,\n",
       "           8.97117108e-02,  3.27343680e-02, -2.51081754e-02],\n",
       "         [ 9.26711969e-03,  6.20251521e-02, -5.39838634e-02, ...,\n",
       "           4.58890274e-02, -8.39679092e-02,  5.24192676e-02],\n",
       "         [-1.55502986e-02, -5.97858848e-03, -1.10391229e-01, ...,\n",
       "           7.64831752e-02,  4.64045405e-02, -8.02373979e-03],\n",
       "         ...,\n",
       "         [-5.93828894e-02,  5.90290991e-04,  1.22890584e-02, ...,\n",
       "          -4.67195958e-02,  5.04171290e-02,  6.88467771e-02],\n",
       "         [-7.92032555e-02, -2.30142772e-02, -3.02939881e-02, ...,\n",
       "          -7.55713205e-04, -3.42620015e-02,  1.42147401e-02],\n",
       "         [ 4.63981554e-02,  8.35456550e-02,  4.54283170e-02, ...,\n",
       "          -1.78314429e-02, -1.46261556e-02, -7.66812358e-03]]],\n",
       "\n",
       "\n",
       "       [[[-1.69480033e-02, -3.16062197e-03,  2.98355445e-02, ...,\n",
       "           7.53895286e-03,  4.05428465e-03, -3.02605727e-03],\n",
       "         [-1.83936041e-02,  1.31284734e-02, -1.43003920e-02, ...,\n",
       "          -1.73365921e-02, -5.43923117e-03,  5.44424122e-03],\n",
       "         [-1.21265687e-02, -2.83979028e-02, -7.25147594e-03, ...,\n",
       "           8.73884372e-03, -6.13151258e-03, -1.29284821e-02],\n",
       "         ...,\n",
       "         [-3.44687179e-02, -9.37402807e-03, -7.08695222e-03, ...,\n",
       "           2.16694735e-02, -1.87233556e-02,  4.81219497e-03],\n",
       "         [ 9.92896408e-03, -1.98749658e-02,  8.93250573e-03, ...,\n",
       "          -1.08621409e-02, -1.16368020e-02, -6.52772142e-04],\n",
       "         [ 2.79137865e-02, -3.51403318e-02, -1.31444447e-02, ...,\n",
       "          -6.65739691e-03, -1.11792525e-02,  2.20970451e-05]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[-6.46433160e-02, -5.25661919e-04,  1.52067151e-02, ...,\n",
       "           5.90431057e-02,  1.01502724e-01,  7.49153346e-02],\n",
       "         [ 1.27168251e-02,  3.57518643e-02, -5.76550514e-02, ...,\n",
       "          -1.11562826e-01, -1.40029043e-02,  8.53670985e-02],\n",
       "         [-7.12149441e-02, -5.87964728e-02, -5.81808239e-02, ...,\n",
       "          -7.72256218e-03, -1.50007950e-02,  1.48816388e-02],\n",
       "         ...,\n",
       "         [ 3.40761468e-02, -8.01477656e-02,  7.31329173e-02, ...,\n",
       "          -4.73962799e-02,  5.32735251e-02,  8.89004953e-03],\n",
       "         [ 1.22437574e-01, -1.04271844e-01, -2.76856925e-02, ...,\n",
       "          -1.73477847e-02,  3.88947427e-02, -1.60903875e-02],\n",
       "         [ 2.55195722e-02, -6.85869008e-02, -3.84753458e-02, ...,\n",
       "           1.72636926e-03, -5.98519482e-02, -3.98768000e-02]]],\n",
       "\n",
       "\n",
       "       [[[-2.86751509e-01,  1.03498951e-01, -7.47228786e-02, ...,\n",
       "          -1.56047106e-01, -4.79815155e-02, -4.11116779e-02],\n",
       "         [-2.20404878e-01,  3.50276195e-02, -5.43602742e-02, ...,\n",
       "           2.00745508e-01, -1.48359805e-01, -1.23407580e-02],\n",
       "         [ 3.25942159e-01,  2.90274382e-01, -2.61270422e-02, ...,\n",
       "          -1.94448188e-01,  6.64253831e-02, -7.76573718e-02],\n",
       "         ...,\n",
       "         [ 2.63133049e-01,  3.29880342e-02, -6.00558519e-01, ...,\n",
       "          -3.18161994e-02,  6.94412813e-02,  1.28608048e-02],\n",
       "         [ 1.11820854e-01, -6.23840749e-01,  2.46543869e-01, ...,\n",
       "           7.36755366e-03,  2.87210643e-01, -8.44725817e-02],\n",
       "         [-1.48190692e-01, -1.87858388e-01,  6.02501817e-03, ...,\n",
       "           6.09731339e-02,  1.51929721e-01,  6.18167641e-03]]],\n",
       "\n",
       "\n",
       "       [[[-4.57976498e-02, -2.70362437e-01,  3.21614891e-02, ...,\n",
       "           5.87959439e-02,  4.85920459e-01, -1.54109433e-01],\n",
       "         [ 3.72805268e-01, -3.26608539e-01,  2.27615833e-01, ...,\n",
       "           1.57556027e-01,  1.70106277e-01, -2.49547303e-01],\n",
       "         [-4.96536400e-03, -3.19902092e-01,  5.23035601e-02, ...,\n",
       "           3.10346216e-01, -7.96234757e-02,  8.60225260e-02],\n",
       "         ...,\n",
       "         [-2.10463136e-01, -9.54049826e-02,  4.29834798e-02, ...,\n",
       "          -4.33535948e-02, -1.29665071e-02, -1.23558849e-01],\n",
       "         [-1.96913034e-01,  6.38561770e-02,  2.08238959e-01, ...,\n",
       "          -3.17688078e-01,  1.46188691e-01,  9.78041291e-02],\n",
       "         [-5.66571727e-02, -2.27106735e-01,  1.44313633e-01, ...,\n",
       "          -7.02380016e-02, -3.35877500e-02,  1.73840553e-01]]]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.transpose(0,1,3,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch mapping "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_test = nn.BatchNorm2d(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "bn1_mean  = load_parameter(\"baidu_models/baidu_en8k/params/___batch_norm_0__.w1\")\n",
    "bn1_var   = load_parameter(\"baidu_models/baidu_en8k/params/___batch_norm_0__.w2\")\n",
    "bn1_gamma = load_parameter(\"baidu_models/baidu_en8k/params/___batch_norm_0__.w0\")\n",
    "bn1_beta  = load_parameter(\"baidu_models/baidu_en8k/params/___batch_norm_0__.wbias\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_test.bias.data         = torch.from_numpy(bn1_beta)\n",
    "batch_test.weight.data       = torch.from_numpy(bn1_gamma)\n",
    "batch_test.running_mean.data = torch.from_numpy(bn1_mean)\n",
    "batch_test.running_var.data  = torch.from_numpy(bn1_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_dict = {\"bias\"        :torch.from_numpy(bn1_beta),\n",
    "               \"weight\"      : torch.from_numpy(bn1_gamma),\n",
    "               \"running_mean\": torch.from_numpy(bn1_mean),\n",
    "               \"running_var\" : torch.from_numpy(bn1_var),\n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 32, 81, 2208])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_batch = batch_test(result)\n",
    "result_batch.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "for key, value in batch_test.state_dict().items():\n",
    "    if key == 'num_batches_tracked':\n",
    "        continue\n",
    "    print(value.size())\n",
    "    assert torch.all(torch.eq(value, weight_dict[key] ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conv_bn_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class conv_bn_mask(nn.Module):\n",
    "    def __init__(self, ichannel, ochannel, kernel_size, padding, stride, bias=False, track_running_stats=False):\n",
    "        super(conv_bn_mask, self).__init__()\n",
    "        self.conv = nn.Conv2d(ichannel, ochannel, kernel_size=kernel_size, padding=padding, stride=stride, bias=bias)\n",
    "        self.bn = nn.BatchNorm2d(ochannel, track_running_stats=track_running_stats)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_bn_mask_layer = conv_bn_mask(1, 32, kernel_size=(41,11), padding=(20, 5), stride=(2,3), track_running_stats=True)\n",
    "result_conv_bn_mask = conv_bn_mask_layer.forward(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_weights = {\"conv.weight\"    : torch.from_numpy(conv1_weights),\n",
    "                      \"bn.bias\"        : torch.from_numpy(bn1_beta),\n",
    "                      \"bn.weight\"      : torch.from_numpy(bn1_gamma),\n",
    "                      \"bn.running_mean\": torch.from_numpy(bn1_mean),\n",
    "                      \"bn.running_var\" : torch.from_numpy(bn1_var)\n",
    "                     }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IncompatibleKeys(missing_keys=[], unexpected_keys=[])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_bn_mask_layer.load_state_dict(pretrained_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_dict = conv_bn_mask_layer.state_dict()\n",
    "for key, value in check_dict.items():\n",
    "    if key == 'bn.num_batches_tracked':\n",
    "        continue\n",
    "    assert torch.all(torch.eq(value, pretrained_weights[key]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 32, 81, 2208])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = torch.rand((1,1,161,6624))\n",
    "result = conv_bn_mask_layer.forward(input)\n",
    "result.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "flatten = result.view(1, -1, 2208)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2592, 2208])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flatten.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0750, 0.6854, 0.1815],\n",
       "        [0.0151, 0.4943, 0.6329],\n",
       "        [0.8049, 0.5829, 0.0303]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = torch.ByteTensor([[1]*3,[1]*3, [0]*3])\n",
    "hehe = torch.rand((3,3))\n",
    "hehe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0750, 0.6854, 0.1815, 0.0151, 0.4943, 0.6329])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.masked_select(hehe,mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = torch.zeros([6, 1, 10,10], dtype=torch.float)\n",
    "mask[:,:,3:7,3:7] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "class mask(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(mask, self).__init__()\n",
    "        \n",
    "    def forward(self,x, batch_info):\n",
    "        c1,c2, w1,w2, h1,h2 = batch_info\n",
    "        mask = torch.zeros_like(x, dtype=torch.float)\n",
    "        mask[c1:c2, w1:w2, h1:h2] = 1\n",
    "        return x * mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_layer = mask()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def VariableRecurrent(batch_sizes, inner):\n",
    "    def forward(input, hidden, weight):\n",
    "        output = []\n",
    "        input_offset = 0\n",
    "        last_batch_size = batch_sizes[0]\n",
    "        hiddens = []\n",
    "        flat_hidden = not isinstance(hidden, tuple)\n",
    "        if flat_hidden:\n",
    "            hidden = (hidden,)\n",
    "        for batch_size in batch_sizes:\n",
    "            step_input = input[input_offset:input_offset + batch_size]\n",
    "            input_offset += batch_size\n",
    "\n",
    "            dec = last_batch_size - batch_size\n",
    "            if dec > 0:\n",
    "                hiddens.append(tuple(h[-dec:] for h in hidden))\n",
    "                hidden = tuple(h[:-dec] for h in hidden)\n",
    "            last_batch_size = batch_size\n",
    "\n",
    "            if flat_hidden:\n",
    "                hidden = (inner(step_input, hidden[0], *weight),)\n",
    "            else:\n",
    "                hidden = inner(step_input, hidden, *weight)\n",
    "\n",
    "            output.append(hidden[0])\n",
    "        hiddens.append(hidden)\n",
    "        hiddens.reverse()\n",
    "\n",
    "        hidden = tuple(torch.cat(h, 0) for h in zip(*hiddens))\n",
    "        assert hidden[0].size(0) == batch_sizes[0]\n",
    "        if flat_hidden:\n",
    "            hidden = hidden[0]\n",
    "        output = torch.cat(output, 0)\n",
    "\n",
    "        return hidden, output\n",
    "    \n",
    "    return forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([[11]*3,[12]*3, [13]*3])\n",
    "b = torch.tensor([[21]*3,[22]*3, [23]*3, [24]*3])\n",
    "c = torch.tensor([[31]*3,[32]*3, [33]*3, [34]*3, [35]*3])\n",
    "seq = nn.utils.rnn.pack_sequence([c,b,a], )\n",
    "input, batch_sizes, _,_ = seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PackedSequence(data=tensor([[31, 31, 31],\n",
       "        [21, 21, 21],\n",
       "        [11, 11, 11],\n",
       "        [32, 32, 32],\n",
       "        [22, 22, 22],\n",
       "        [12, 12, 12],\n",
       "        [33, 33, 33],\n",
       "        [23, 23, 23],\n",
       "        [13, 13, 13],\n",
       "        [34, 34, 34],\n",
       "        [24, 24, 24],\n",
       "        [35, 35, 35]]), batch_sizes=tensor([3, 3, 3, 2, 1]), sorted_indices=None, unsorted_indices=None)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq.unsorted_indices = seq.to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq.unsorted_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gru_test(input, hidden, weight):\n",
    "    h, c = hidden\n",
    "    hy = h + 1\n",
    "    cy = c + 1\n",
    "    return hy, cy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "forward = VariableRecurrent(batch_sizes, gru_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((tensor([5, 4, 3]), tensor([5, 4, 3])),\n",
       " tensor([1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 5]))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forward(input, (torch.tensor([0]*3), torch.tensor([0]*3)), [0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
