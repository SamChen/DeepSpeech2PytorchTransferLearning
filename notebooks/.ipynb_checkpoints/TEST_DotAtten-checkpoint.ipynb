{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from model_utils.custom_attentions import DotAtten_Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.4222e-03, -8.9895e-04,  1.2248e-03],\n",
       "        [ 3.4170e-04,  2.9886e-04, -2.7204e-04],\n",
       "        [-7.0874e-05, -1.3734e-04,  9.2684e-05]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = DotAtten_Layer(embed_dim=3, window_size=3, key_dim=3, value_dim=3)\n",
    "\n",
    "input=torch.rand(4, 20, 3)\n",
    "output=torch.rand(4, 20, 3)\n",
    "\n",
    "lengths = torch.tensor([20, 20, 20, 10])\n",
    "for i, l in enumerate([20, 20, 20, 10]):\n",
    "    output[i,l:,:] = 0\n",
    "    \n",
    "output_hat = []\n",
    "output_weights = []\n",
    "query = torch.rand(4,1,3)\n",
    "\n",
    "for i in range(20):\n",
    "    mask, stop_edge = test.attention_mask(lengths, 20, query_index=i)\n",
    "    \n",
    "    if stop_edge is not None:\n",
    "        input = torch.narrow(input, dim=0, start=0, length=stop_edge)\n",
    "        query = torch.narrow(query, dim=0, start=0, length=stop_edge)\n",
    "        mask = torch.narrow(mask, dim=0, start=0, length=stop_edge)\n",
    "        blank_out = torch.zeros(4-stop_edge, 1, 3).type_as(out)\n",
    "        blank_wgts = torch.zeros(4-stop_edge, *out_wgts.shape[1:]).type_as(out_wgts)\n",
    "    \n",
    "    out, out_wgts = test(query, key=input, value=input, attn_mask=mask)\n",
    "    \n",
    "    if stop_edge is not None:\n",
    "        out = torch.cat([out, blank_out], dim=0)\n",
    "        out_wgts = torch.cat([out_wgts, blank_wgts], dim=0)\n",
    "        \n",
    "    output_hat.append(out)\n",
    "    output_weights.append(out_wgts)\n",
    "    query = out\n",
    "    \n",
    "output_hat = torch.cat(output_hat, dim=1) \n",
    "output_weights = torch.cat(output_weights, dim=1) \n",
    "\n",
    "output_hat = nn.utils.rnn.pack_padded_sequence(output_hat, lengths=lengths, batch_first=True)\n",
    "output = nn.utils.rnn.pack_padded_sequence(output, lengths=lengths, batch_first=True)\n",
    "\n",
    "loss = (output[0] - output_hat[0]).abs().mean()\n",
    "loss.backward()\n",
    "\n",
    "test.wk.weight.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_utils.network import deepspeech_LocalDotAttenLayers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input=torch.rand(4, 1000, 3)\n",
    "lengths = torch.tensor([1000, 5, 4, 3])\n",
    "\n",
    "output = torch.rand(4, 1000, 4)\n",
    "for i, l in enumerate([1000, 5, 4, 3]):\n",
    "    output[i,l:,:] = 0\n",
    "\n",
    "input = nn.utils.rnn.pack_padded_sequence(input, lengths, batch_first=True)\n",
    "output = nn.utils.rnn.pack_padded_sequence(output, lengths, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dp = deepspeech_LocalDotAttenLayers(embed_dim=2, window_size=3, init_strategy=\"random\", input_dim=3, output_dim=4, device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.1182, -0.1292]],\n",
      "\n",
      "        [[-0.2783, -0.0370]],\n",
      "\n",
      "        [[-0.1715, -0.0945]],\n",
      "\n",
      "        [[-0.0116, -0.2026]]], grad_fn=<UnsafeViewBackward>)\n",
      "tensor([[[-0.2127, -0.0727]],\n",
      "\n",
      "        [[-0.2637, -0.0474]],\n",
      "\n",
      "        [[-0.2124, -0.0692]],\n",
      "\n",
      "        [[-0.0557, -0.1748]]], grad_fn=<UnsafeViewBackward>)\n",
      "tensor([[[-0.1933, -0.0840]],\n",
      "\n",
      "        [[-0.2637, -0.0474]],\n",
      "\n",
      "        [[-0.2124, -0.0692]],\n",
      "\n",
      "        [[-0.0557, -0.1747]]], grad_fn=<UnsafeViewBackward>)\n",
      "3\n",
      "tensor([[[-0.1658, -0.1008]],\n",
      "\n",
      "        [[-0.2637, -0.0474]],\n",
      "\n",
      "        [[-0.2124, -0.0692]],\n",
      "\n",
      "        [[ 0.0000,  0.0000]]], grad_fn=<CatBackward>)\n",
      "2\n",
      "tensor([[[-0.1179, -0.1320]],\n",
      "\n",
      "        [[-0.2552, -0.0551]],\n",
      "\n",
      "        [[ 0.0000,  0.0000]],\n",
      "\n",
      "        [[ 0.0000,  0.0000]]], grad_fn=<CatBackward>)\n",
      "1\n",
      "tensor([[[-0.1224, -0.1291]],\n",
      "\n",
      "        [[ 0.0000,  0.0000]],\n",
      "\n",
      "        [[ 0.0000,  0.0000]],\n",
      "\n",
      "        [[ 0.0000,  0.0000]]], grad_fn=<CatBackward>)\n",
      "1\n",
      "tensor([[[-0.1478, -0.1132]],\n",
      "\n",
      "        [[ 0.0000,  0.0000]],\n",
      "\n",
      "        [[ 0.0000,  0.0000]],\n",
      "\n",
      "        [[ 0.0000,  0.0000]]], grad_fn=<CatBackward>)\n",
      "1\n",
      "tensor([[[-0.0912, -0.1486]],\n",
      "\n",
      "        [[ 0.0000,  0.0000]],\n",
      "\n",
      "        [[ 0.0000,  0.0000]],\n",
      "\n",
      "        [[ 0.0000,  0.0000]]], grad_fn=<CatBackward>)\n",
      "1\n",
      "tensor([[[-0.0394, -0.1802]],\n",
      "\n",
      "        [[ 0.0000,  0.0000]],\n",
      "\n",
      "        [[ 0.0000,  0.0000]],\n",
      "\n",
      "        [[ 0.0000,  0.0000]]], grad_fn=<CatBackward>)\n",
      "1\n",
      "tensor([[[-0.0188, -0.1954]],\n",
      "\n",
      "        [[ 0.0000,  0.0000]],\n",
      "\n",
      "        [[ 0.0000,  0.0000]],\n",
      "\n",
      "        [[ 0.0000,  0.0000]]], grad_fn=<CatBackward>)\n",
      "1\n",
      "tensor([[[-0.0194, -0.1972]],\n",
      "\n",
      "        [[ 0.0000,  0.0000]],\n",
      "\n",
      "        [[ 0.0000,  0.0000]],\n",
      "\n",
      "        [[ 0.0000,  0.0000]]], grad_fn=<CatBackward>)\n",
      "1\n",
      "tensor([[[-0.0533, -0.1736]],\n",
      "\n",
      "        [[ 0.0000,  0.0000]],\n",
      "\n",
      "        [[ 0.0000,  0.0000]],\n",
      "\n",
      "        [[ 0.0000,  0.0000]]], grad_fn=<CatBackward>)\n",
      "1\n",
      "tensor([[[-0.0820, -0.1557]],\n",
      "\n",
      "        [[ 0.0000,  0.0000]],\n",
      "\n",
      "        [[ 0.0000,  0.0000]],\n",
      "\n",
      "        [[ 0.0000,  0.0000]]], grad_fn=<CatBackward>)\n",
      "1\n",
      "tensor([[[-0.0665, -0.1652]],\n",
      "\n",
      "        [[ 0.0000,  0.0000]],\n",
      "\n",
      "        [[ 0.0000,  0.0000]],\n",
      "\n",
      "        [[ 0.0000,  0.0000]]], grad_fn=<CatBackward>)\n",
      "1\n",
      "tensor([[[-0.1195, -0.1317]],\n",
      "\n",
      "        [[ 0.0000,  0.0000]],\n",
      "\n",
      "        [[ 0.0000,  0.0000]],\n",
      "\n",
      "        [[ 0.0000,  0.0000]]], grad_fn=<CatBackward>)\n",
      "1\n",
      "tensor([[[-0.1116, -0.1374]],\n",
      "\n",
      "        [[ 0.0000,  0.0000]],\n",
      "\n",
      "        [[ 0.0000,  0.0000]],\n",
      "\n",
      "        [[ 0.0000,  0.0000]]], grad_fn=<CatBackward>)\n",
      "1\n",
      "tensor([[[-0.1133, -0.1344]],\n",
      "\n",
      "        [[ 0.0000,  0.0000]],\n",
      "\n",
      "        [[ 0.0000,  0.0000]],\n",
      "\n",
      "        [[ 0.0000,  0.0000]]], grad_fn=<CatBackward>)\n",
      "1\n",
      "tensor([[[-0.1313, -0.1209]],\n",
      "\n",
      "        [[ 0.0000,  0.0000]],\n",
      "\n",
      "        [[ 0.0000,  0.0000]],\n",
      "\n",
      "        [[ 0.0000,  0.0000]]], grad_fn=<CatBackward>)\n",
      "1\n",
      "tensor([[[-0.1119, -0.1336]],\n",
      "\n",
      "        [[ 0.0000,  0.0000]],\n",
      "\n",
      "        [[ 0.0000,  0.0000]],\n",
      "\n",
      "        [[ 0.0000,  0.0000]]], grad_fn=<CatBackward>)\n",
      "1\n",
      "tensor([[[-0.0754, -0.1570]],\n",
      "\n",
      "        [[ 0.0000,  0.0000]],\n",
      "\n",
      "        [[ 0.0000,  0.0000]],\n",
      "\n",
      "        [[ 0.0000,  0.0000]]], grad_fn=<CatBackward>)\n"
     ]
    }
   ],
   "source": [
    "output_hat, _, output_weight = test_dp(input, lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-3.2015e-03, -4.8934e-04],\n",
       "        [ 1.1112e-05,  1.3192e-05]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dp.zero_grad()\n",
    "loss = (output[0] - output_hat[0]).abs().mean()\n",
    "loss\n",
    "loss.backward()\n",
    "test_dp.atten.wk.weight.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'ba'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-ea37aa25b156>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mba\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'ba'"
     ]
    }
   ],
   "source": [
    "loss.ba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[nan, nan, nan],\n",
       "        [nan, nan, nan]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dp.input_proj.weight.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
