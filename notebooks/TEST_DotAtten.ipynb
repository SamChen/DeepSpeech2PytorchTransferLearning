{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from model_utils.custom_attentions import DotAtten_Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.5331e-03, -1.4304e-03, -1.6214e-03],\n",
       "        [ 3.6288e-05,  7.2617e-05, -1.3357e-05],\n",
       "        [ 1.8650e-03, -1.0807e-03, -1.1935e-03]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = DotAtten_Layer(embed_dim=3, window_size=3, key_dim=3, value_dim=3)\n",
    "\n",
    "input=torch.rand(4, 20, 3)\n",
    "output=torch.rand(4, 20, 3)\n",
    "\n",
    "lengths = torch.tensor([20, 20, 20, 10])\n",
    "for i, l in enumerate([20, 20, 20, 10]):\n",
    "    output[i,l:,:] = 0\n",
    "    \n",
    "output_hat = []\n",
    "output_weights = []\n",
    "query = torch.rand(4,1,3)\n",
    "\n",
    "for i in range(20):\n",
    "    mask, stop_edge = test.attention_mask(lengths, 20, query_index=i)\n",
    "    \n",
    "    if stop_edge is not None:\n",
    "        input = torch.narrow(input, dim=0, start=0, length=stop_edge)\n",
    "        query = torch.narrow(query, dim=0, start=0, length=stop_edge)\n",
    "        mask = torch.narrow(mask, dim=0, start=0, length=stop_edge)\n",
    "        blank_out = torch.zeros(4-stop_edge, 1, 3).type_as(out)\n",
    "        blank_wgts = torch.zeros(4-stop_edge, *out_wgts.shape[1:]).type_as(out_wgts)\n",
    "    \n",
    "    out, out_wgts = test(query, key=input, value=input, attn_mask=mask)\n",
    "    \n",
    "    if stop_edge is not None:\n",
    "        out = torch.cat([out, blank_out], dim=0)\n",
    "        out_wgts = torch.cat([out_wgts, blank_wgts], dim=0)\n",
    "        \n",
    "    output_hat.append(out)\n",
    "    output_weights.append(out_wgts)\n",
    "    query = out\n",
    "    \n",
    "output_hat = torch.cat(output_hat, dim=1) \n",
    "output_weights = torch.cat(output_weights, dim=1) \n",
    "\n",
    "output_hat = nn.utils.rnn.pack_padded_sequence(output_hat, lengths=lengths, batch_first=True)\n",
    "output = nn.utils.rnn.pack_padded_sequence(output, lengths=lengths, batch_first=True)\n",
    "\n",
    "loss = (output[0] - output_hat[0]).abs().mean()\n",
    "loss.backward()\n",
    "\n",
    "test.wk.weight.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_utils.network import deepspeech_LocalDotAttenLayers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input=torch.rand(4, 1000, 3)\n",
    "lengths = torch.tensor([1000, 5, 4, 3])\n",
    "\n",
    "output = torch.rand(4, 1000, 4)\n",
    "for i, l in enumerate([1000, 5, 4, 3]):\n",
    "    output[i,l:,:] = 0\n",
    "\n",
    "input = nn.utils.rnn.pack_padded_sequence(input, lengths, batch_first=True)\n",
    "output = nn.utils.rnn.pack_padded_sequence(output, lengths, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dp = deepspeech_LocalDotAttenLayers(embed_dim=2, window_size=3, init_strategy=\"random\", input_dim=3, output_dim=4, device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_hat, _, output_weight = test_dp(input, lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0016, 0.0012],\n",
       "        [0.0042, 0.0030]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dp.zero_grad()\n",
    "loss = (output[0] - output_hat[0]).abs().mean()\n",
    "loss\n",
    "loss.backward()\n",
    "test_dp.atten.wk.weight.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'ba'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-ea37aa25b156>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mba\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'ba'"
     ]
    }
   ],
   "source": [
    "loss.ba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[nan, nan, nan],\n",
       "        [nan, nan, nan]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dp.input_proj.weight.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
