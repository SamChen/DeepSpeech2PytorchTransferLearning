basic:
  # Please change these absolut paths for your computer
  ds2_model_path: "abspath/to/deepspeech/model/baidu_en8k/params/"
  language_model_path: "abspath/to/deepspeech/model/lm/common_crawl_00.prune01111.trie.klm"
  vocab_filepath: "abspath/to/deepspeech/model/baidu_en8k/vocab.txt"
  mean_std_filepath: "abspath/to/deepspeech/model/baidu_en8k/mean_std.npz"

  exp_root_path: "abspath/to/deepspeech/notebooks/example/"
  model: "network.deepspeech_orig"
  # default load the deepspeech2 model from paddlepaddle

  # this is for load pytorch pretrained model
  pt_model_path:
  use_pt_model: False
  device: "cpu"
  augmentation_config_name: "augmentation.config"


train:
  num_total_epochs: 40
  num_iterations_validate: 200
  num_sorted_epoch: 3
  num_workers: 10
  batch_size: 16
  max_duration: 20
  min_duration: 3
  segmented: True

test:
  num_workers: 10
  batch_size: 16
  max_duration: 10000
  min_duration: 3
  segmented: True

#TODO: a special module should check the validation of these files and some special dirs
data:
  train_csv: "example.csv"
  val_csv:   "example.csv"
  test_csv:  "example.csv"

optimizer:
  learning_rate: 7e-6
  included_layer_keywords:
    - deepspeech_bottleneck
    - bigru2
    - bigru1
    - bigru0
    - conv_bn_mask1
    - conv_bn_mask0
  excluded_layer_keywords: 
  # Here, you can specify learning rate for each layer. 
  # This will overwrite the previous learning rate on that the specified layer.
  specific_lr_dict: {deepspeech_bottleneck: 7e-5}
    
  
# multi-scheduler options have not been impletemented yet.
scheduler:
  scheduler_name:
  gamma: 1.0
