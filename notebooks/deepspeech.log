nohup: ignoring input
[INFO 2020-01-21 19:01:23,401 model.py:286] begin to initialize the external scorer for decoding
[INFO 2020-01-21 19:01:32,606 model.py:296] language model: is_character_based = 0, max_order = 5, dict_size = 400000
[INFO 2020-01-21 19:01:32,701 model.py:297] end initializing scorer
[INFO 2020-01-21 19:01:32,715 model.py:149] Start training process
[INFO 2020-01-21 19:01:48,133 model.py:163] global_iter: 0, loss/train: 1.2411081790924072, loss/val: 1.411910789353507
[INFO 2020-01-21 19:14:38,624 model.py:163] global_iter: 200, loss/train: 1.0401668548583984, loss/val: 1.189160602433341
[INFO 2020-01-21 19:27:35,570 model.py:163] global_iter: 400, loss/train: 0.9449778199195862, loss/val: 1.1000248108591353
[INFO 2020-01-21 19:40:33,255 model.py:163] global_iter: 600, loss/train: 0.7249773740768433, loss/val: 1.048309279339654
[INFO 2020-01-21 19:53:27,728 model.py:163] global_iter: 800, loss/train: 0.8505684733390808, loss/val: 1.0192768701485224
[INFO 2020-01-21 20:06:25,369 model.py:163] global_iter: 1000, loss/train: 0.6756414771080017, loss/val: 0.996154363666262
[INFO 2020-01-21 20:19:24,000 model.py:163] global_iter: 1200, loss/train: 0.7866483926773071, loss/val: 0.9762893744877407
[INFO 2020-01-21 20:32:21,065 model.py:163] global_iter: 1400, loss/train: 0.6966259479522705, loss/val: 0.9599977220807757
[INFO 2020-01-21 20:45:17,961 model.py:163] global_iter: 1600, loss/train: 0.6196322441101074, loss/val: 0.946415730885097
[INFO 2020-01-21 20:58:13,473 model.py:163] global_iter: 1800, loss/train: 0.8606370687484741, loss/val: 0.9345619976520538
[INFO 2020-01-21 21:11:09,519 model.py:163] global_iter: 2000, loss/train: 0.7678259611129761, loss/val: 0.9230959670884269
[INFO 2020-01-21 21:24:07,524 model.py:163] global_iter: 2200, loss/train: 0.7367396354675293, loss/val: 0.9141811685902732
[INFO 2020-01-21 21:37:07,595 model.py:163] global_iter: 2400, loss/train: 0.6556950807571411, loss/val: 0.9062619251864297
[INFO 2020-01-21 21:50:02,265 model.py:163] global_iter: 2600, loss/train: 0.5584186315536499, loss/val: 0.8999026673180717
[INFO 2020-01-21 22:03:00,337 model.py:163] global_iter: 2800, loss/train: 0.5211087465286255, loss/val: 0.8932131784302848
[INFO 2020-01-21 22:15:59,194 model.py:163] global_iter: 3000, loss/train: 0.5271730422973633, loss/val: 0.8868626483849117
[INFO 2020-01-21 22:28:57,155 model.py:163] global_iter: 3200, loss/train: 0.5776621699333191, loss/val: 0.8816584689276559
[INFO 2020-01-21 22:41:55,369 model.py:163] global_iter: 3400, loss/train: 0.799462080001831, loss/val: 0.8769714449133191
[INFO 2020-01-21 22:54:53,738 model.py:163] global_iter: 3600, loss/train: 0.6567490696907043, loss/val: 0.8730461299419403
[INFO 2020-01-21 23:07:51,169 model.py:163] global_iter: 3800, loss/train: 0.5022218227386475, loss/val: 0.8691462065492358
[INFO 2020-01-21 23:20:48,253 model.py:163] global_iter: 4000, loss/train: 0.48837798833847046, loss/val: 0.865567650113787
[INFO 2020-01-21 23:33:47,835 model.py:163] global_iter: 4200, loss/train: 0.4790460467338562, loss/val: 0.8612154849937984
[INFO 2020-01-21 23:46:45,441 model.py:163] global_iter: 4400, loss/train: 0.6745465397834778, loss/val: 0.85812047123909
[INFO 2020-01-21 23:59:42,997 model.py:163] global_iter: 4600, loss/train: 0.6101794242858887, loss/val: 0.8551544887678963
[INFO 2020-01-22 00:12:40,439 model.py:163] global_iter: 4800, loss/train: 0.5202198624610901, loss/val: 0.8525131855692182
[INFO 2020-01-22 00:25:40,648 model.py:163] global_iter: 5000, loss/train: 0.5121792554855347, loss/val: 0.8508665561676025
[INFO 2020-01-22 00:38:39,172 model.py:163] global_iter: 5200, loss/train: 0.5247292518615723, loss/val: 0.8479573215757098
[INFO 2020-01-22 00:51:37,279 model.py:163] global_iter: 5400, loss/train: 0.48573365807533264, loss/val: 0.8469811379909515
[INFO 2020-01-22 01:04:33,263 model.py:163] global_iter: 5600, loss/train: 0.5425833463668823, loss/val: 0.8447647265025547
[INFO 2020-01-22 01:17:31,989 model.py:163] global_iter: 5800, loss/train: 0.4315280020236969, loss/val: 0.8428314881665366
[INFO 2020-01-22 01:30:29,350 model.py:163] global_iter: 6000, loss/train: 0.4782283306121826, loss/val: 0.840912469795772
[INFO 2020-01-22 01:43:26,264 model.py:163] global_iter: 6200, loss/train: 0.6551293730735779, loss/val: 0.839225594486509
[INFO 2020-01-22 01:56:25,681 model.py:163] global_iter: 6400, loss/train: 0.46808314323425293, loss/val: 0.8382539749145508
[INFO 2020-01-22 02:09:23,834 model.py:163] global_iter: 6600, loss/train: 0.5727255344390869, loss/val: 0.8372874855995178
[INFO 2020-01-22 02:22:20,904 model.py:163] global_iter: 6800, loss/train: 0.5351210832595825, loss/val: 0.8363123748983655
[INFO 2020-01-22 02:35:17,108 model.py:163] global_iter: 7000, loss/train: 0.39045947790145874, loss/val: 0.835242245878492
[INFO 2020-01-22 02:48:15,855 model.py:163] global_iter: 7200, loss/train: 0.5569774508476257, loss/val: 0.8347654172352382
[INFO 2020-01-22 03:01:11,802 model.py:163] global_iter: 7400, loss/train: 0.5248095989227295, loss/val: 0.8340366014412471
[INFO 2020-01-22 03:14:10,493 model.py:163] global_iter: 7600, loss/train: 0.4919235110282898, loss/val: 0.8326451139790672
[INFO 2020-01-22 03:27:07,931 model.py:163] global_iter: 7800, loss/train: 0.45116424560546875, loss/val: 0.8312280774116516
[INFO 2020-01-22 03:40:04,768 model.py:163] global_iter: 8000, loss/train: 0.4615313410758972, loss/val: 0.8310183925288064
[INFO 2020-01-22 03:53:01,178 model.py:163] global_iter: 8200, loss/train: 0.44453370571136475, loss/val: 0.8308971907411303
[INFO 2020-01-22 04:06:00,086 model.py:163] global_iter: 8400, loss/train: 0.3719800114631653, loss/val: 0.8318347036838531
[INFO 2020-01-22 04:18:55,501 model.py:163] global_iter: 8600, loss/train: 0.4134240746498108, loss/val: 0.8313452047961098
[INFO 2020-01-22 04:31:53,063 model.py:163] global_iter: 8800, loss/train: 0.36938196420669556, loss/val: 0.8307511806488037
[INFO 2020-01-22 04:44:54,111 model.py:163] global_iter: 9000, loss/train: 0.4551287889480591, loss/val: 0.8303099657808032
[INFO 2020-01-22 04:57:50,811 model.py:163] global_iter: 9200, loss/train: 0.33251631259918213, loss/val: 0.8291760214737484
[INFO 2020-01-22 05:10:48,541 model.py:163] global_iter: 9400, loss/train: 0.47347769141197205, loss/val: 0.8296615651675633
[INFO 2020-01-22 05:23:47,477 model.py:163] global_iter: 9600, loss/train: 0.4528768062591553, loss/val: 0.8294186847550529
[INFO 2020-01-22 05:36:43,904 model.py:163] global_iter: 9800, loss/train: 0.4279101490974426, loss/val: 0.8295432925224304
[INFO 2020-01-22 05:49:40,583 model.py:163] global_iter: 10000, loss/train: 0.40909385681152344, loss/val: 0.829973259142467
[INFO 2020-01-22 06:02:39,727 model.py:163] global_iter: 10200, loss/train: 0.39523375034332275, loss/val: 0.8305637495858329
[INFO 2020-01-22 06:15:34,786 model.py:163] global_iter: 10400, loss/train: 0.4146656394004822, loss/val: 0.8298258142811912
[INFO 2020-01-22 06:28:30,459 model.py:163] global_iter: 10600, loss/train: 0.3990528881549835, loss/val: 0.8293302186897823
[INFO 2020-01-22 06:41:28,580 model.py:163] global_iter: 10800, loss/train: 0.38946884870529175, loss/val: 0.8298809741224561
[INFO 2020-01-22 06:54:27,661 model.py:163] global_iter: 11000, loss/train: 0.3721771240234375, loss/val: 0.8303747219698769
[INFO 2020-01-22 07:07:24,636 model.py:163] global_iter: 11200, loss/train: 0.39598244428634644, loss/val: 0.8302234155791146
[INFO 2020-01-22 07:20:20,210 model.py:163] global_iter: 11400, loss/train: 0.542256236076355, loss/val: 0.8297357388905117
[INFO 2020-01-22 07:33:14,633 model.py:163] global_iter: 11600, loss/train: 0.3942686915397644, loss/val: 0.8292682085718427
[INFO 2020-01-22 07:46:12,998 model.py:163] global_iter: 11800, loss/train: 0.35649484395980835, loss/val: 0.8301586806774139
[INFO 2020-01-22 07:59:07,772 model.py:163] global_iter: 12000, loss/train: 0.31772804260253906, loss/val: 0.8302627376147679
[INFO 2020-01-22 08:12:04,131 model.py:163] global_iter: 12200, loss/train: 0.42691725492477417, loss/val: 0.8309202917984554
[INFO 2020-01-22 08:25:00,268 model.py:163] global_iter: 12400, loss/train: 0.3781786561012268, loss/val: 0.8307166269847325
[INFO 2020-01-22 08:37:56,847 model.py:163] global_iter: 12600, loss/train: 0.43705952167510986, loss/val: 0.8306728303432465
[INFO 2020-01-22 08:50:53,219 model.py:163] global_iter: 12800, loss/train: 0.45749056339263916, loss/val: 0.8304802136761802
[INFO 2020-01-22 09:03:51,302 model.py:163] global_iter: 13000, loss/train: 0.4464302659034729, loss/val: 0.8305373702730451
[INFO 2020-01-22 09:16:49,239 model.py:163] global_iter: 13200, loss/train: 0.3837844729423523, loss/val: 0.8314944761140006
[INFO 2020-01-22 09:29:48,161 model.py:163] global_iter: 13400, loss/train: 0.27478349208831787, loss/val: 0.8322165650980813
[INFO 2020-01-22 09:42:44,755 model.py:163] global_iter: 13600, loss/train: 0.29907625913619995, loss/val: 0.83145130106381
[INFO 2020-01-22 09:55:40,062 model.py:163] global_iter: 13800, loss/train: 0.4022677540779114, loss/val: 0.8315085385526929
[INFO 2020-01-22 10:08:38,506 model.py:163] global_iter: 14000, loss/train: 0.4012409448623657, loss/val: 0.831238580601556
[INFO 2020-01-22 10:21:35,483 model.py:163] global_iter: 14200, loss/train: 0.4813787341117859, loss/val: 0.8315531100545611
[INFO 2020-01-22 10:34:34,278 model.py:163] global_iter: 14400, loss/train: 0.43806153535842896, loss/val: 0.8324005603790283
[INFO 2020-01-22 10:47:29,696 model.py:163] global_iter: 14600, loss/train: 0.3037509620189667, loss/val: 0.8327039778232574
[INFO 2020-01-22 11:00:27,649 model.py:163] global_iter: 14800, loss/train: 0.42941513657569885, loss/val: 0.833219941173281
[INFO 2020-01-22 11:13:25,003 model.py:163] global_iter: 15000, loss/train: 0.2993484437465668, loss/val: 0.8338799178600311
[INFO 2020-01-22 11:26:24,005 model.py:163] global_iter: 15200, loss/train: 0.5085712671279907, loss/val: 0.833499584879194
[INFO 2020-01-22 11:39:21,702 model.py:163] global_iter: 15400, loss/train: 0.49519097805023193, loss/val: 0.8348968965666634
[INFO 2020-01-22 11:52:20,100 model.py:163] global_iter: 15600, loss/train: 0.2673562169075012, loss/val: 0.8347076262746539
[INFO 2020-01-22 12:05:16,449 model.py:163] global_iter: 15800, loss/train: 0.5672709941864014, loss/val: 0.8357659663472857
[INFO 2020-01-22 12:18:16,136 model.py:163] global_iter: 16000, loss/train: 0.3821379840373993, loss/val: 0.8363157170159476
[INFO 2020-01-22 12:31:08,975 model.py:163] global_iter: 16200, loss/train: 0.24662458896636963, loss/val: 0.8363103227955955
[INFO 2020-01-22 12:44:09,023 model.py:163] global_iter: 16400, loss/train: 0.44038718938827515, loss/val: 0.8370373802525657
[INFO 2020-01-22 12:57:07,455 model.py:163] global_iter: 16600, loss/train: 0.35313546657562256, loss/val: 0.8371792180197579
[INFO 2020-01-22 13:10:03,705 model.py:163] global_iter: 16800, loss/train: 0.4266400933265686, loss/val: 0.8370951456683022
[INFO 2020-01-22 13:23:01,588 model.py:163] global_iter: 17000, loss/train: 0.30324310064315796, loss/val: 0.8391082329409463
[INFO 2020-01-22 13:36:00,112 model.py:163] global_iter: 17200, loss/train: 0.4194178283214569, loss/val: 0.8390340421880994
[INFO 2020-01-22 13:48:58,050 model.py:163] global_iter: 17400, loss/train: 0.3336513042449951, loss/val: 0.8404143026896885
[INFO 2020-01-22 14:01:55,593 model.py:163] global_iter: 17600, loss/train: 0.35103437304496765, loss/val: 0.8385161885193416
[INFO 2020-01-22 14:14:55,409 model.py:163] global_iter: 17800, loss/train: 0.283488929271698, loss/val: 0.8399585996355329
[INFO 2020-01-22 14:27:51,540 model.py:163] global_iter: 18000, loss/train: 0.39691486954689026, loss/val: 0.8412888944149017
[INFO 2020-01-22 14:40:48,701 model.py:163] global_iter: 18200, loss/train: 0.30539166927337646, loss/val: 0.8432476690837315
[INFO 2020-01-22 14:53:43,219 model.py:171] global_iter: 18400, loss/train: 0.3257461190223694, loss/val: 0.841187277010509
